# Operation Analytics and Investigating Metric Spike

## Project Overview
This project is centered around **Operational Analytics**, a key process that involves analyzing a company's end-to-end operations. The aim is to identify areas for improvement by deriving actionable insights from various datasets. The focus includes investigating metric spikes and understanding sudden changes in critical metrics such as user engagement or throughput.

You will take on the role of a Lead Data Analyst, responsible for analyzing job performance, user growth, retention, and engagement metrics using **Advanced SQL** skills. This project consists of two main case studies:

- **Case Study 1: Job Data Analysis**
- **Case Study 2: Investigating Metric Spike**

## Project Structure
The project is divided into two main sections, with different tasks assigned for each case study:

1. **Case Study 1: Job Data Analysis**
   - Analyze job review performance and event throughput.
   - Focus on jobs reviewed over time, throughput analysis, language share analysis, and detection of duplicate rows.

2. **Case Study 2: Investigating Metric Spike**
   - Investigate key metrics related to user engagement, growth, and retention.
   - Analyze weekly engagement, retention, user growth, and email engagement metrics.

## Tech Stack
The following tools and technologies were used to complete this project:

- **Database Management**: MySQL Workbench
- **Database**: MySQL (CSV data import and table creation)
- **Programming Language**: SQL (for data queries and analysis)
- **Documentation and Reporting**: Microsoft Word (for creating reports), Google Drive (for file sharing)

## Approach
The approach to this project was broken down as follows:

1. **Data Import**: 
   - Created a database in MySQL Workbench.
   - Imported CSV files into MySQL and created the necessary tables.

2. **Data Analysis**: 
   - Performed the required analysis by writing SQL queries to address the tasks outlined in each case study.
   - Measured key metrics like job reviews per hour, throughput, language share, user engagement, and retention over time.

3. **Report Generation**:
   - Created a detailed report to summarize the findings, key insights, and results derived from the analysis.
   - Included SQL query snapshots and outputs in the report for reference.

## Tasks and Queries
### Case Study 1: Job Data Analysis
1. **Jobs Reviewed Over Time**:
   - Objective: Calculate the number of jobs reviewed per hour for each day in November 2020.

2. **Throughput Analysis**:
   - Objective: Calculate the 7-day rolling average of throughput (number of events per second).

3. **Language Share Analysis**:
   - Objective: Calculate the percentage share of each language over the last 30 days.

4. **Duplicate Rows Detection**:
   - Objective: Identify duplicate rows in the `job_data` table.

### Case Study 2: Investigating Metric Spike
1. **Weekly User Engagement**:
   - Objective: Measure user activeness on a weekly basis.

2. **User Growth Analysis**:
   - Objective: Analyze the growth of users over time for a product.

3. **Weekly Retention Analysis**:
   - Objective: Analyze the retention of users weekly after signing up.

4. **Weekly Engagement Per Device**:
   - Objective: Measure user engagement on a weekly basis per device.

5. **Email Engagement Analysis**:
   - Objective: Analyze how users are engaging with the email service.

## Insights
Some key insights derived from the project include:
- Fluctuations in job throughput could indicate operational bottlenecks, highlighting the need for resource allocation adjustments.
- Language distribution metrics revealed key trends in user behavior based on content language preference, which can guide content creation strategies.
- Spike analysis revealed anomalies in user engagement that require further investigation into external factors like marketing campaigns or technical issues.

## Results
Through this project, I gained deeper insights into:
- Investigating and understanding sudden spikes in critical operational metrics.
- Using SQL to perform advanced analysis of job data and user engagement.
- The importance of rolling metrics like 7-day averages for smooth performance tracking.
- The significance of real-time and historical data in decision-making processes.

## How to Run the Project
1. **Clone the Repository**:  
   Clone the project repository or download the project files.

2. **Database Setup**:  
   Import the CSV files into MySQL Workbench and set up the necessary tables.

3. **Execute SQL Queries**:  
   Run the provided SQL queries in MySQL Workbench to perform the analysis.

4. **Generate Report**:  
   After performing the analysis, compile the SQL queries and give a report (PDF or PPT) as required.

## Report
For more detailed insights and the final report, access the project report above.
